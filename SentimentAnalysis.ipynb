{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Import fundamentals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.util.testing as tm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import TglStemmer\n",
    "\n",
    "# Import nltk and download punkt, wordnet\n",
    "import nltk\n",
    "\n",
    "#import warning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import word_tokenize and stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer \n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# I will keep the resulting plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable Jupyter Notebook's intellisense\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# We want to see whole content (non-truncated)\n",
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lynn93630469 Support my little sister in her ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yan, tama yan. Dapat lang na nasa #1 &amp;amp; #2 ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kabi-kbila na ang utang ko dahil sa online cla...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GoodmorningðŸŒž Online class is realðŸ˜‚</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>umay sa globe fiber. goodluck pag may online c...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets     Label\n",
       "0  @lynn93630469 Support my little sister in her ...   Neutral\n",
       "1  Yan, tama yan. Dapat lang na nasa #1 &amp; #2 ...   Neutral\n",
       "2  Kabi-kbila na ang utang ko dahil sa online cla...  Negative\n",
       "3                 GoodmorningðŸŒž Online class is realðŸ˜‚  Positive\n",
       "4  umay sa globe fiber. goodluck pag may online c...  Negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tweets\n",
    "tweets = pd.read_csv(\"F.csv\")\n",
    "\n",
    "# Print the first five rows\n",
    "display(tweets.head())\n",
    "\n",
    "# Print the summary statistics\n",
    "#print(tweets.describe())\n",
    "\n",
    "# Drop duplicated rows\n",
    "tweets.drop_duplicates(inplace=True)\n",
    "\n",
    "# Print the info\n",
    "#print(tweets.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the text file containing the Filipino Stopwords based from https://github.com/stopwords-iso/stopwords-tl\n",
    "\n",
    "file = open(\"StopWords/flstopwords.txt\", \"r\", encoding=\"utf8\")\n",
    "flstopwords = file.read().split(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support little sister school buying laptop onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yan tama yan lang nasa amp tags natin aba pamb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utang online class panload lng need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>online class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>umay globe fiber goodluck pag online class talaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mad last october first semester terpaksa jahin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>online class ayoko mag enroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sinusulit lang yung year online class law scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>today using lot khursus online class watching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know hinhindi tlaga pwede online class nakatul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wrong timing laptop nasira kelan need online c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>buong araw nasa upuan online class charot donb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slept good night next morning woke feeling ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>facebook twitter viber instagram tiktok online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>online class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Processed\n",
       "0   support little sister school buying laptop onl...\n",
       "1   yan tama yan lang nasa amp tags natin aba pamb...\n",
       "2                 utang online class panload lng need\n",
       "3                                        online class\n",
       "4   umay globe fiber goodluck pag online class talaga\n",
       "5   mad last october first semester terpaksa jahin...\n",
       "6                       online class ayoko mag enroll\n",
       "7   sinusulit lang yung year online class law scho...\n",
       "8   today using lot khursus online class watching ...\n",
       "9   know hinhindi tlaga pwede online class nakatul...\n",
       "10  wrong timing laptop nasira kelan need online c...\n",
       "11  buong araw nasa upuan online class charot donb...\n",
       "12  slept good night next morning woke feeling ref...\n",
       "13  facebook twitter viber instagram tiktok online...\n",
       "14                                       online class"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_tweets(tweet):\n",
    "            \n",
    "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "    tweet = re.sub(r\"can't\", \"can not\", tweet)\n",
    "    tweet = re.sub(r\"n't\", \" not\", tweet)\n",
    "    tweet = re.sub(r\"'ve\", \" have\", tweet)\n",
    "    tweet = re.sub(r\"'ll\", \" will\", tweet)\n",
    "    tweet = re.sub(r\"'re\", \" are\", tweet)\n",
    "    \n",
    "    tweet = re.sub(r\"'di\", \"hindi\", tweet)\n",
    "    \n",
    "    tweet = re.sub(r\"di\", \"hindi\", tweet)\n",
    "    \n",
    "    # Remove links\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    #remove numbers\n",
    "    tweet = re.sub(r'\\d','', tweet)\n",
    "    \n",
    "    # Remove mentions and hashtag\n",
    "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "   \n",
    "    # clean the words\n",
    "    clean = word_tokenize(tweet)\n",
    "\n",
    "    # Remove the English stop words\n",
    "    clean = [token for token in clean if token not in stopwords.words(\"english\")]\n",
    "    \n",
    "    #Remove the Filipino stop words\n",
    "    clean = [token for token in clean if token not in flstopwords]\n",
    "    \n",
    "    # Remove non-alphabetic characters and keep the words contains three or more letters\n",
    "    clean = [token for token in clean if token.isalpha() and len(token)>2]\n",
    "    \n",
    "    clean = ' '.join(clean)\n",
    "    return clean\n",
    "    \n",
    "# Call the function and store the result into a new column\n",
    "tweets[\"Processed\"] = tweets[\"Tweets\"].str.lower().apply(process_tweets)\n",
    "#tweets[\"Content\"].str.lower().apply(process_tweets)\n",
    "\n",
    "display(tweets[[\"Processed\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeWithPOS(text):\n",
    "    # Lemmatization & Stemming according to POS tagging\n",
    "\n",
    "    word_list = word_tokenize(text)\n",
    "    rev = []\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    stemmer = PorterStemmer() \n",
    "    for word, tag in pos_tag(word_list):\n",
    "        if tag.startswith('J'):\n",
    "            w = lemmatizer.lemmatize(word, pos='a')\n",
    "        elif tag.startswith('V'):\n",
    "            w = lemmatizer.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('N'):\n",
    "            w = lemmatizer.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('R'):\n",
    "            w = lemmatizer.lemmatize(word, pos='r')\n",
    "        else:\n",
    "            w = word\n",
    "        w = stemmer.stem(w)\n",
    "        rev.append(w)\n",
    "    tweet = ' '.join(rev)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Processed\"] = tweets[\"Processed\"].apply(NormalizeWithPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enstopwords = set(stopwords.words('english'))\n",
    "        \n",
    "# Initialize a Tf-idf Vectorizer\n",
    "vectorizer = TfidfVectorizer(idf_id=True,max_df=0.90, min_df=2, stop_words=enstopwords and flstopwords)\n",
    "\n",
    "# Fit and transform the vectorizer corpus = [str (item) for item in corpus]\n",
    "tfidf_matrix = vectorizer.fit_transform(str (item) for item in tweets[\"Processed\"])\n",
    "\n",
    "# Let's see what we have\n",
    "tfidf_matrix\n",
    "\n",
    "# Create a DataFrame for tf-idf vectors and display the first five rows\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns= vectorizer.get_feature_names())\n",
    "display(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features and the target\n",
    "X = tfidf_matrix\n",
    "#X = tweets[\"Processed\"] \n",
    "y = tweets[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = .20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The type of X_train_dtm and X_test_dtm is scipy.sparse.csr.csr_matrix\n",
    "#Before model selection, You need to convert it into numpy sparse format using toarray() method\n",
    "print('Before conversion:')\n",
    "print('X_train_dtm: ', type(X_train))\n",
    "print('X_test_dtm: ', type(X_test))\n",
    "X_train = X_train.toarray()\n",
    "X_test  = X_test.toarray()\n",
    "print('After conversion:')\n",
    "print('X_train_dtm: ', type(X_train))\n",
    "print('X_test_dtm: ', type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB #this works best for text classification\n",
    "mnb = MultinomialNB()\n",
    "#train our algorithm\n",
    "mnb.fit(X_train, y_train)\n",
    "#Test the trained classifier\n",
    "predicted_class = mnb.predict(X_test)\n",
    "print('Accuracy of MNB for this dataset: %3.2f' %  accuracy_score(y_test, predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"ang ganda ng online class\"\n",
    "words = vectorizer.transform([str (item) for item in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str (item) for item in words)\n",
    "mnb.predict(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model\n",
    "pickle.dump(mnb, open(\"model.pkl\", 'wb'))\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(mnb, 'model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = load('model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"ang ganda ng online class\"\n",
    "words = vectorizer.transform(str (item) for item in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.predict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
